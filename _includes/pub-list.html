<!doctype html>
<html lang="en" class="no-js">
  <body>
    <div id="main" role="main">
      <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
        <meta itemprop="headline" content="Publications">
        <meta itemprop="description" content="Publications">
        <div class="page__inner-wrap">
          <header>
            <h1 class="page__title" itemprop="headline">Selected Publications</h1>
          </header>
          <section class="page__content" itemprop="text">
            For a full list of publications, please refer to <a
              href="https://scholar.google.com/citations?user=CWcnL7YAAAAJ&hl=en" target="_blank">my Google Scholar
              page</a><br /><br />

            <div class="row">
              <div class="col-sm-3">
                <center>
                  <figure>
                    <img src="https://shtoshni.github.io/papers/imgs/State_Probing.jpg"
                      style="max-width:140px;margin-top: calc(10px);">
                  </figure>
                </center>
              </div>
              <div class="col-sm-pull-9">
                <br />
                <p style="font-size:normal; color:black;text-align:left;">
                  <strong> <a href="https://aclanthology.org/2022.findings-emnlp.397.pdf" target="_blank">
                      Baked-in State Probing </a></strong><br />
                  Shubham Toshniwal, Sam Wiseman, Karen Livescu, Kevin Gimpel <br />
                  Findings of EMNLP (short) <br />
                </p>
              </div>
            </div>
            <br />

            <div class="row">
              <div class="col-sm-3">
                <center>
                  <figure>
                    <img src="https://shtoshni.github.io/papers/imgs/morphy_chess_out.jpg"
                      style="max-width:125px;margin-top: calc(-5px);">
                  </figure>
                </center>
              </div>
              <div class="col-sm-pull-9">
                <br />
                <p style="font-size:normal; color:black;text-align:left;">
                  <strong> <a href="https://arxiv.org/pdf/2102.13249.pdf" target="_blank">
                      Chess as a Testbed for Language Model State Tracking</a></strong><br />
                  Shubham Toshniwal, Sam Wiseman, Karen Livescu, Kevin Gimpel <br />
                  AAAI 2022<br />
                  <a href="https://github.com/shtoshni/learning-chess-blindfolded" target="_blank"><i
                      class="fa-brands fa-github"></i></a>
                  <a href="https://colab.research.google.com/drive/125y4MpnSWAakoSE5My9jGMtBExbjqTpW?usp=sharing"
                    target="_blank"><i class="fa-solid fa-terminal"></i></a>
                  <!-- <a href="https://colab.research.google.com/drive/125y4MpnSWAakoSE5My9jGMtBExbjqTpW?usp=sharing" target="_blank">[Colab - Play against LM]</a> -->
                  <a href="https://shtoshni.github.io/papers/slides/learning_chess_blindfolded.pdf" target="_blank"><i
                      class="fa-solid fa-file-powerpoint"></i></a>
                  <a href="https://www.youtube.com/watch?v=WUb0pVJy7iQ&ab_channel=PyTorchLightning"><i
                      class="fa-brands fa-youtube"></i></a>
                  <a href="https://shtoshni.github.io/papers/bibs/toshniwal2022chess.bib" target="_blank">[bib]</a>
                </p>
              </div>
            </div>
            <br />
            <br />

            <div class="row">
              <div class="col-sm-3">
                <center>
                  <figure>
                    <img src="https://shtoshni.github.io/papers/imgs/coref_generalization.jpg"
                      style="max-width:150px;margin-top: calc(20px);">
                  </figure>
                </center>
              </div>
              <div class="col-sm-pull-9">
                <br />
                <p style="font-size:normal; color:black;text-align:left;">
                  <strong> <a href="https://arxiv.org/pdf/2102.13249.pdf" target="_blank">
                      On Generalization in Coreference Resolution</a></strong><br />
                  Shubham Toshniwal, Patrick Xia, Sam Wiseman, Karen Livescu, Kevin Gimpel <br />
                  <a href="https://sites.google.com/view/crac2021/" target="_blank">CRAC@EMNLP (<i>Best Short
                      Paper</i>)</a><br />
                  <a href="https://github.com/shtoshni/fast-coref" target="_blank"><i class="fa-brands fa-github"></i></a>
                  <a href="https://colab.research.google.com/drive/11ejXc1wDqzUxpgRH1nLvqEifAX30Z71_?usp=sharing"
                    target="_blank"><i class="fa-solid fa-terminal"></i></a>
                  <a href="https://shtoshni.github.io/papers/slides/emnlp_2021_generalization.pdf" target="_blank"><i
                      class="fa-solid fa-file-powerpoint"></i></a>
                  <a href="https://shtoshni.github.io/papers/bibs/toshniwal2021generalization.bib"
                    target="_blank">[bib]</a>
                </p>
              </div>
            </div>
            <br />


            <div class="row">
              <div class="col-sm-3">
                <center>
                  <figure>
                    <img src="https://shtoshni.github.io/papers/imgs/long_doc.jpg"
                      style="max-width:130px; margin-top: calc(-20px);">
                  </figure>
                </center>
              </div>
              <div class="col-sm-pull-9">
                <p style="font-size:large; color:black;text-align:left;">
                  <strong> <a href="https://arxiv.org/pdf/2010.02807.pdf" target="_blank">Learning to Ignore: Long
                      Document Coreference with Bounded Memory Neural Networks</a></strong><br />
                  Shubham Toshniwal, Sam Wiseman, Allyson Ettinger, Karen Livescu, Kevin Gimpel <br />
                  EMNLP 2020 (short)<br />
                  <a href="https://github.com/shtoshni/long-doc-coref" target="_blank"><i
                      class="fa-brands fa-github"></i></a>
                  <a href="https://colab.research.google.com/drive/1aG37Fkgg4GILFvpGE7YALEf-TWJlZgTe?usp=sharing"
                    target="_blank"><i class="fa-solid fa-terminal"></i></a>
                  <a href="https://shtoshni.github.io/papers/slides/emnlp_2020_bounded.pdf" target="_blank"><i
                      class="fa-solid fa-file-powerpoint"></i></a>
                  <a href="https://slideslive.com/38938926/learning-to-ignore-long-document-coreference-with-bounded-memory-neural-networks"
                    target="_blank"><i class="fa-solid fa-video"></i></a>
                  <a href="https://shtoshni.github.io/resources/coref/litbank_html/" target="_blank">[LitBank Data in
                    HTML]</a>
                  <a href="https://shtoshni.github.io/papers/bibs/toshniwal2020bounded.bib" target="_blank">[bib]</a>
                </p>
              </div>
            </div>
            <br />

            <div class="row">
              <div class="col-sm-3">
                <figure>
                  <img src="https://shtoshni.github.io/papers/imgs/prosody.jpg" style="max-width:130px;">
                </figure>
              </div>
              <div class="col-sm-pull-9">
                <br />
                <p style="font-size:large; color:black;text-align:left;">
                  <strong><a href="https://www.aclweb.org/anthology/N18-1007.pdf" target="_blank"> Parsing Speech: A
                      Neural Approach to Integrating Lexical and Acoustic-Prosodic Information </a> </strong><br />
                  Trang Tran*, <em>Shubham Toshniwal*</em>, Mohit Bansal, Kevin Gimpel, Karen Livescu, Mari Ostendorf
                  <br />
                  NAACL HLT 2018 (Oral)<br />
                  <a href="https://github.com/shtoshni/speech_parsing" target="_blank"><i
                      class="fa-brands fa-github"></i></a>
                  <a href="https://shtoshni.github.io/papers/slides/parsing.pdf" target="_blank"><i
                      class="fa-solid fa-file-powerpoint"></i></a>
                  <a href="https://shtoshni.github.io/papers/bibs/parsing.bib" target="_blank">[bib]</a>
                </p>
              </div>
            </div>
            <br />

            <div class="row">
              <div class="col-sm-3">
                <figure>
                  <img src="https://shtoshni.github.io/papers/imgs/multitask.jpg"
                    style="max-width:150px; max-height:150px;">
                </figure>
              </div>

              <div class="col-sm-pull-9">
                <p style="font-size:large; color:black;text-align:left;">
                  <strong> <a href="https://arxiv.org/pdf/1704.01631.pdf" target="_blank">Multitask Learning with
                      Low-Level Auxiliary Tasks for Encoder-Decoder Based Speech Recognition </a> </strong><br />
                  <em>Shubham Toshniwal</em>, Hao Tang, Liang Lu, Karen Livescu <br />
                  Interspeech 2017 (Oral)<br />
                  <a href="https://shtoshni.github.io/papers/slides/msld_2017.pdf" target="_blank"><i
                      class="fa-solid fa-file-powerpoint"></i></a>
                  <a href="https://shtoshni.github.io/papers/slides/ml_asr_snl.pdf" target="_blank">[Summary]</a>
                  <a href="https://shtoshni.github.io/papers/bibs/mtl_interspeech_2017.bib" target="_blank">[bib]</a>
                </p>
              </div>
            </div>
          </section>
          <footer class="page__meta"></footer>
        </div>
      </article>
    </div>
  </body>
</html>